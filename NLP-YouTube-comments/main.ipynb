{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1><center> Предсказание \"виральности комментария\" с помощью методов машинного обучения</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Введение](#introduction)\n",
    "\n",
    "[2.1. Сбор данных](#data-collection)\n",
    "\n",
    "[2.2. Импорт библиотек и данных](#data-import)\n",
    "\n",
    "[2.3. Предобработка данных](#data-preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Введение <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка естественного языка (Natural Language Processing, NLP) — направление машинного обучения, изучающее анализ и синтез текстов на естественном языке. На данный момент NLP — одна из самых важных сфер машинного обучения в том числе благодаря появлению BERT и ChatGPT.\n",
    "\n",
    "Среди применений NLP можно выделить:\n",
    "\n",
    "- Классификация текстов\n",
    "- Извлечение информации и ключевых слов из текстов \n",
    "- Генерация текст-текст\n",
    "- Машинный перевод и т.д.\n",
    "\n",
    "В рамках этого проекта я буду использовать NLP методы для того, чтобы определять *сколько лайков может получить комментарий на YouTube (Fox News)* на основе их содержания, а также дополнительных метаданных.\n",
    "\n",
    "**Задачи**:\n",
    "- Сбор и предобработка данных\n",
    "- Разведовательный анализ данных (Explanatory Data Analysis, EDA)\n",
    "- Обучение модели\n",
    "- Оценка результатов\n",
    "\n",
    "**Данные**. В качестве данных для обучения модели я буду использовать комментарии с канала Fox News на Youtube. Я соберу их вручную с помощью Google API.\n",
    "\n",
    "**Модель**. В рамках этого проекта я хочу получить опыт c SOTA архитектурой Tranformers. Про выбор модели подробнее в соответствующем разделе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Сбор данных <a class=\"anchor\" id=\"data-collection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных для обучения будут использоваться комментарии с YouTube-канала одного из самых популярных Американских СМИ — Fox News. Результаты полученные с помощью модели, обученной на этих данных, конечно, не могут использоваться где угодно, однако, в этой работе, я хочу, в первую очередь, получить практический опыт реализации NLP моделей.\n",
    "\n",
    "Итак, для сбора данных я использовал *YouTube Data API v3*.\n",
    "\n",
    "В репозитории проекта на GitHub имеются два Python скрипта — *video_parser.py* и *comments_parser.py*.\n",
    "\n",
    "***video_parser.py*** — получает информацию о 50 самых популярных видео с канала в виде словаря\n",
    "```json\n",
    "{\n",
    "\"videoId\": \"UqE8IYUXsBs\",\n",
    "\"videoPublishedAt\": \"2025-07-18T15:45:02Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "***comments_parser.py*** — получает 100 популярных комментариев к каждому, полученному предыдущим скриптом видео. И формирует финальный датасет\n",
    "\n",
    "| commentId                      | videoId      | textOriginal                                                                 | likeCount | videoPublishedAt       | commentPublishedAt    | commentUpdatedAt      |\n",
    "|--------------------------------|--------------|-----------------------------------------------------------------------------|-----------|------------------------|-----------------------|-----------------------|\n",
    "| UgwwQfnW75VHyFU8oCh4AaABAg     | UqE8IYUXsBs  | Read more: https://www.foxnews.com/us/feds-california-home-depot-raid-nabs... | 44        | 2025-07-18T15:45:02Z  | 2025-07-18T17:18:07Z | 2025-07-18T17:18:07Z |\n",
    "| UgwL5M-S_ZkgZP-TaPJ4AaABAg     | UqE8IYUXsBs  | Start removing these judges and politicians that allow this mess in the first place! | 2315      | 2025-07-18T15:45:02Z  | 2025-07-18T16:50:39Z | 2025-07-18T16:50:39Z |\n",
    "| UgyCiXsqEo-3mBy_fUx4AaABAg     | UqE8IYUXsBs  | He's been arrested 67 times, he shouldn't be here                            | 1488      | 2025-07-18T15:45:02Z  | 2025-07-18T16:51:11Z | 2025-07-18T16:51:11Z |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Импорт библиотек и данных <a class=\"anchor\" id=\"data-import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sentencepiece import SentencePieceTrainer, SentencePieceProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>videoPublishedAt</th>\n",
       "      <th>commentPublishedAt</th>\n",
       "      <th>commentUpdatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgwwQfnW75VHyFU8oCh4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>Read more: https://www.foxnews.com/us/feds-cal...</td>\n",
       "      <td>44</td>\n",
       "      <td>2025-07-18T15:45:02Z</td>\n",
       "      <td>2025-07-18T17:18:07Z</td>\n",
       "      <td>2025-07-18T17:18:07Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgwL5M-S_ZkgZP-TaPJ4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>Start removing these judges and politicians th...</td>\n",
       "      <td>2315</td>\n",
       "      <td>2025-07-18T15:45:02Z</td>\n",
       "      <td>2025-07-18T16:50:39Z</td>\n",
       "      <td>2025-07-18T16:50:39Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgyCiXsqEo-3mBy_fUx4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>He's been arrested 67 times, he shouldn't be here</td>\n",
       "      <td>1488</td>\n",
       "      <td>2025-07-18T15:45:02Z</td>\n",
       "      <td>2025-07-18T16:51:11Z</td>\n",
       "      <td>2025-07-18T16:51:11Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgyfSvY23tYFDfpzbvx4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>He sliced the tires.\\n They left that informat...</td>\n",
       "      <td>1117</td>\n",
       "      <td>2025-07-18T15:45:02Z</td>\n",
       "      <td>2025-07-18T23:52:04Z</td>\n",
       "      <td>2025-07-18T23:52:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugxu4iFba7FZ06CfMK54AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>67 arrests since 1986!!  Jail the judges who f...</td>\n",
       "      <td>70</td>\n",
       "      <td>2025-07-18T15:45:02Z</td>\n",
       "      <td>2025-07-19T17:46:43Z</td>\n",
       "      <td>2025-07-19T17:46:43Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    commentId      videoId  \\\n",
       "0  UgwwQfnW75VHyFU8oCh4AaABAg  UqE8IYUXsBs   \n",
       "1  UgwL5M-S_ZkgZP-TaPJ4AaABAg  UqE8IYUXsBs   \n",
       "2  UgyCiXsqEo-3mBy_fUx4AaABAg  UqE8IYUXsBs   \n",
       "3  UgyfSvY23tYFDfpzbvx4AaABAg  UqE8IYUXsBs   \n",
       "4  Ugxu4iFba7FZ06CfMK54AaABAg  UqE8IYUXsBs   \n",
       "\n",
       "                                        textOriginal  likeCount  \\\n",
       "0  Read more: https://www.foxnews.com/us/feds-cal...         44   \n",
       "1  Start removing these judges and politicians th...       2315   \n",
       "2  He's been arrested 67 times, he shouldn't be here       1488   \n",
       "3  He sliced the tires.\\n They left that informat...       1117   \n",
       "4  67 arrests since 1986!!  Jail the judges who f...         70   \n",
       "\n",
       "       videoPublishedAt    commentPublishedAt      commentUpdatedAt  \n",
       "0  2025-07-18T15:45:02Z  2025-07-18T17:18:07Z  2025-07-18T17:18:07Z  \n",
       "1  2025-07-18T15:45:02Z  2025-07-18T16:50:39Z  2025-07-18T16:50:39Z  \n",
       "2  2025-07-18T15:45:02Z  2025-07-18T16:51:11Z  2025-07-18T16:51:11Z  \n",
       "3  2025-07-18T15:45:02Z  2025-07-18T23:52:04Z  2025-07-18T23:52:04Z  \n",
       "4  2025-07-18T15:45:02Z  2025-07-19T17:46:43Z  2025-07-19T17:46:43Z  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    filepath_or_buffer='parsed_content/comments.csv',\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   commentId           5000 non-null   object\n",
      " 1   videoId             5000 non-null   object\n",
      " 2   textOriginal        4999 non-null   object\n",
      " 3   likeCount           5000 non-null   int64 \n",
      " 4   videoPublishedAt    5000 non-null   object\n",
      " 5   commentPublishedAt  5000 non-null   object\n",
      " 6   commentUpdatedAt    5000 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, датасет содержит 5000 комментариев со следующими характеристиками:\n",
    "\n",
    "- commentId — уникальный идентификатор комментария\n",
    "- videoId — уникальный идентификатор видео\n",
    "- textOriginal — полный текст комментария\n",
    "- likeCount — количество лайков под комментарием (*целевая переменная*)\n",
    "- videoPublishedAt — timestamp публикации видео\n",
    "- commentPublishedAt — timestamp публикации комментария\n",
    "- commentUpdatedAt - timestamp редактирования комментария"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этапе предобработки данных нужно будет обработать пропущенное значение в textOriginal, привести типы данных, а также сделать временные столбцы более информативными, нормализировать данные, токенизировать комментарии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Предобработка данных <a class=\"anchor\" id=\"data-preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим этапом я выбрал предобаботку данных, потому что она будет включать в себя feature engineering и в EDA я бы хотел увидеть распределения и характеристики всех фичей перед обучением модели. Если на этапе EDA обнаружаться выбросы или еще какие-то проблемы с данными они будут обработаны позже (после EDA).\n",
    "\n",
    "Начну с того, что удалю пропуски и дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4971 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   commentId           4971 non-null   object\n",
      " 1   videoId             4971 non-null   object\n",
      " 2   textOriginal        4970 non-null   object\n",
      " 3   likeCount           4971 non-null   int64 \n",
      " 4   videoPublishedAt    4971 non-null   object\n",
      " 5   commentPublishedAt  4971 non-null   object\n",
      " 6   commentUpdatedAt    4971 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 310.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset='textOriginal')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить было удалено 29 одинаковых комментариев.\n",
    "\n",
    "Теперь удалю пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4970 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   commentId           4970 non-null   object\n",
      " 1   videoId             4970 non-null   object\n",
      " 2   textOriginal        4970 non-null   object\n",
      " 3   likeCount           4970 non-null   int64 \n",
      " 4   videoPublishedAt    4970 non-null   object\n",
      " 5   commentPublishedAt  4970 non-null   object\n",
      " 6   commentUpdatedAt    4970 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 310.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также стоит удалить комментарии, которые редактировались, потому что мы не можем знать какую именно версию комментария пользователи одобрили лайком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4755 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   commentId           4755 non-null   object\n",
      " 1   videoId             4755 non-null   object\n",
      " 2   textOriginal        4755 non-null   object\n",
      " 3   likeCount           4755 non-null   int64 \n",
      " 4   videoPublishedAt    4755 non-null   object\n",
      " 5   commentPublishedAt  4755 non-null   object\n",
      " 6   commentUpdatedAt    4755 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 297.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(data[data['commentPublishedAt'] != data['commentUpdatedAt']].index)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, поскольку в столбцах commentPublishedAt и commentUpdatedAt находятся одинаковые значения стоит удалить последний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['commentUpdatedAt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь датасет содержит 4755 уникальных комментариев.\n",
    "\n",
    "Следующим шагом я преобразую типы данных, для дальнейшей корректной работы с фичами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commentId             string[python]\n",
       "videoId               string[python]\n",
       "textOriginal          string[python]\n",
       "likeCount                      int64\n",
       "videoPublishedAt               int64\n",
       "commentPublishedAt             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['videoPublishedAt'] = pd.to_datetime(\n",
    "    data['videoPublishedAt'], \n",
    "    format='%Y-%m-%dT%H:%M:%SZ', \n",
    "    utc=True\n",
    ")\n",
    "\n",
    "data['commentPublishedAt'] = pd.to_datetime(\n",
    "    data['commentPublishedAt'], \n",
    "    format='%Y-%m-%dT%H:%M:%SZ', \n",
    "    utc=True\n",
    ")\n",
    "\n",
    "data = data.astype({\n",
    "    'commentId' : 'string',\n",
    "    'videoId' : 'string',\n",
    "    'textOriginal' : 'string',\n",
    "    'likeCount' : 'int64',\n",
    "    'videoPublishedAt' : 'int64',\n",
    "    'commentPublishedAt' : 'int64',\n",
    "})\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные приведены к нормальным типам теперь над ними можно безопасно проводить различные операции.\n",
    "\n",
    "Начну с того, что создам новый столбец, который будет хранить время, пройденное с начала публикации до написания комментария."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgwwQfnW75VHyFU8oCh4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>Read more: https://www.foxnews.com/us/feds-cal...</td>\n",
       "      <td>44</td>\n",
       "      <td>5585000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgwL5M-S_ZkgZP-TaPJ4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>Start removing these judges and politicians th...</td>\n",
       "      <td>2315</td>\n",
       "      <td>3937000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgyCiXsqEo-3mBy_fUx4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>He's been arrested 67 times, he shouldn't be here</td>\n",
       "      <td>1488</td>\n",
       "      <td>3969000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgyfSvY23tYFDfpzbvx4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>He sliced the tires.\n",
       " They left that informati...</td>\n",
       "      <td>1117</td>\n",
       "      <td>29222000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugxu4iFba7FZ06CfMK54AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>67 arrests since 1986!!  Jail the judges who f...</td>\n",
       "      <td>70</td>\n",
       "      <td>93701000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    commentId      videoId  \\\n",
       "0  UgwwQfnW75VHyFU8oCh4AaABAg  UqE8IYUXsBs   \n",
       "1  UgwL5M-S_ZkgZP-TaPJ4AaABAg  UqE8IYUXsBs   \n",
       "2  UgyCiXsqEo-3mBy_fUx4AaABAg  UqE8IYUXsBs   \n",
       "3  UgyfSvY23tYFDfpzbvx4AaABAg  UqE8IYUXsBs   \n",
       "4  Ugxu4iFba7FZ06CfMK54AaABAg  UqE8IYUXsBs   \n",
       "\n",
       "                                        textOriginal  likeCount  \\\n",
       "0  Read more: https://www.foxnews.com/us/feds-cal...         44   \n",
       "1  Start removing these judges and politicians th...       2315   \n",
       "2  He's been arrested 67 times, he shouldn't be here       1488   \n",
       "3  He sliced the tires.\n",
       " They left that informati...       1117   \n",
       "4  67 arrests since 1986!!  Jail the judges who f...         70   \n",
       "\n",
       "     commentDelay  \n",
       "0   5585000000000  \n",
       "1   3937000000000  \n",
       "2   3969000000000  \n",
       "3  29222000000000  \n",
       "4  93701000000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['commentDelay'] = data['commentPublishedAt'] - data['videoPublishedAt']\n",
    "\n",
    "data = data.drop(['videoPublishedAt', 'commentPublishedAt'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, так как архитектура целевой модели использует операции с матрицами и алгебру с числами, стоит стандартизировать числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgwwQfnW75VHyFU8oCh4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>Read more: https://www.foxnews.com/us/feds-cal...</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.016787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgwL5M-S_ZkgZP-TaPJ4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>Start removing these judges and politicians th...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgyCiXsqEo-3mBy_fUx4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>He's been arrested 67 times, he shouldn't be here</td>\n",
       "      <td>0.642765</td>\n",
       "      <td>0.013648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgyfSvY23tYFDfpzbvx4AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>He sliced the tires.\n",
       " They left that informati...</td>\n",
       "      <td>0.482505</td>\n",
       "      <td>0.062695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugxu4iFba7FZ06CfMK54AaABAg</td>\n",
       "      <td>UqE8IYUXsBs</td>\n",
       "      <td>67 arrests since 1986!!  Jail the judges who f...</td>\n",
       "      <td>0.030238</td>\n",
       "      <td>0.187929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    commentId      videoId  \\\n",
       "0  UgwwQfnW75VHyFU8oCh4AaABAg  UqE8IYUXsBs   \n",
       "1  UgwL5M-S_ZkgZP-TaPJ4AaABAg  UqE8IYUXsBs   \n",
       "2  UgyCiXsqEo-3mBy_fUx4AaABAg  UqE8IYUXsBs   \n",
       "3  UgyfSvY23tYFDfpzbvx4AaABAg  UqE8IYUXsBs   \n",
       "4  Ugxu4iFba7FZ06CfMK54AaABAg  UqE8IYUXsBs   \n",
       "\n",
       "                                        textOriginal  likeCount  commentDelay  \n",
       "0  Read more: https://www.foxnews.com/us/feds-cal...   0.019006      0.016787  \n",
       "1  Start removing these judges and politicians th...   1.000000      0.013586  \n",
       "2  He's been arrested 67 times, he shouldn't be here   0.642765      0.013648  \n",
       "3  He sliced the tires.\n",
       " They left that informati...   0.482505      0.062695  \n",
       "4  67 arrests since 1986!!  Jail the judges who f...   0.030238      0.187929  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['likeCount', 'commentDelay']] = MinMaxScaler().fit_transform(data[['likeCount', 'commentDelay']])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пришло время к важному этапу в реализции моделей обрабатывающих естественный язык — преобразование текстов в числовые представения — embeddings.\n",
    "\n",
    "Для начала необходимо получить токены из наших данных. NLP модели, которые оперируют текстом, испольщуют понятие токена.\n",
    "\n",
    "Токен — это единица текста, которую спсобен понимать алгоритм. В этой работе я буду использовать современный токенизатор основанный на Byte Pair Encoding (BPE) — Google SentencePiece Tokenizer. Этот метод хорошо подходит под выполняемую задачу, потому что:\n",
    "\n",
    "- люди совершают ошибки при написании коментарии и subword tokenization лучше справляется с подобными ошибками, чем другие способы токенизации\n",
    "- люди используют сленг и неформальную лексику, BPE может улавливать это\n",
    "- может обрабатывать слова не содержащиеся в исходных данных.\n",
    "\n",
    "Начнем с создания обучающих данных для токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_comments_text.txt', 'w', encoding='utf-8') as file:\n",
    "    for text in data['textOriginal']:\n",
    "        file.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=all_comments_text.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: all_comments_text.txt\n",
      "  input_format: \n",
      "  model_prefix: m_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: all_comments_text.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 5140 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=397355\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9504% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=163\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999504\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 5138 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 5138\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 14336\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8680 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2220 size=20 all=2753 active=1740 piece=le\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1400 size=40 all=3426 active=2413 piece=▁l\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=881 size=60 all=3985 active=2972 piece=ld\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=632 size=80 all=4646 active=3633 piece=▁G\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=515 size=100 all=5386 active=4373 piece=ould\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=514 min_freq=38\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=416 size=120 all=5874 active=1482 piece=ith\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=354 size=140 all=6337 active=1945 piece=��li\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=160 all=6762 active=2370 piece=??\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=269 size=180 all=7218 active=2826 piece=ank\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=231 size=200 all=7619 active=3227 piece=ry\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=231 min_freq=35\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=215 size=220 all=7862 active=1221 piece=▁fi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=198 size=240 all=8192 active=1551 piece=▁out\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=180 size=260 all=8526 active=1885 piece=▁te\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=167 size=280 all=8789 active=2148 piece=reat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=154 size=300 all=9016 active=2375 piece=os\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=153 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139 size=320 all=9319 active=1253 piece=▁every\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=340 all=9587 active=1521 piece=▁count\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121 size=360 all=9800 active=1734 piece=▁New\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=380 all=9961 active=1895 piece=▁en\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105 size=400 all=10130 active=2064 piece=emocrat\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=104 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=101 size=420 all=10305 active=1170 piece=▁Jess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=440 all=10502 active=1367 piece=▁Jessica\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=460 all=10742 active=1607 piece=▁Californ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=480 all=10908 active=1773 piece=▁-\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=500 all=11139 active=2004 piece=own\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=81 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=520 all=11308 active=1157 piece=▁bl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=540 all=11457 active=1306 piece=ite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=560 all=11652 active=1501 piece=▁cit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=580 all=11808 active=1657 piece=▁res\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=600 all=11971 active=1820 piece=▁tell\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=620 all=12080 active=1108 piece=▁Let\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=640 all=12200 active=1228 piece=ense\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=660 all=12333 active=1361 piece=▁sc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=680 all=12418 active=1446 piece=▁where\n",
      "bpe_model_train"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "er.cc(268) LOG(INFO) Added: freq=53 size=700 all=12536 active=1564 piece=TH\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=53 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=720 all=12699 active=1146 piece=ani\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=740 all=12822 active=1269 piece=▁Kai\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=760 all=12886 active=1333 piece=▁agents\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=780 all=13009 active=1456 piece=OC\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=800 all=13119 active=1566 piece=▁another\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=46 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=820 all=13229 active=1111 piece=man\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=840 all=13339 active=1221 piece=▁vote\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=860 all=13394 active=1276 piece=erson\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=880 all=13475 active=1357 piece=OM\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=900 all=13630 active=1512 piece=ook\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=920 all=13734 active=1091 piece=▁TR\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=940 all=13850 active=1207 piece=▁USA\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=960 all=13888 active=1245 piece=▁point\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=980 all=13978 active=1335 piece=OL\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1000 all=14063 active=1420 piece=▁working\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=1020 all=14144 active=1082 piece=▁fund\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1040 all=14242 active=1180 piece=▁Rus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1060 all=14306 active=1244 piece=▁🙏\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1080 all=14396 active=1334 piece=▁funny\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=1100 all=14450 active=1388 piece=▁REL\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1120 all=14531 active=1080 piece=▁SH\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1140 all=14611 active=1160 piece=▁left\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1160 all=14674 active=1223 piece=aught\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1180 all=14704 active=1253 piece=ott\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1200 all=14813 active=1362 piece=▁doll\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1220 all=14870 active=1056 piece=▁Mr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1240 all=14914 active=1100 piece=▁since\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1260 all=15007 active=1193 piece=▁Gut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1280 all=15039 active=1225 piece=▁matter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1300 all=15120 active=1306 piece=▁power\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1320 all=15164 active=1043 piece=▁et\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1340 all=15236 active=1115 piece=▁inte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1360 all=15282 active=1161 piece=alk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1380 all=15375 active=1254 piece=sible\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1400 all=15392 active=1271 piece=▁citizen\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1420 all=15496 active=1105 piece=▁etc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1440 all=15504 active=1113 piece=▁looks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1460 all=15521 active=1130 piece=ery\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1480 all=15595 active=1204 piece=▁dif\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1500 all=15621 active=1230 piece=▁crimes\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1520 all=15678 active=1058 piece=rif\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1540 all=15741 active=1121 piece=esome\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1560 all=15774 active=1154 piece=usting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1580 all=15775 active=1155 piece=▁sanctuary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1600 all=15890 active=1270 piece=lege\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1620 all=15910 active=1019 piece=axwell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1640 all=15911 active=1020 piece=▁Congratulations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1660 all=16032 active=1141 piece=▁HR\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1680 all=16122 active=1231 piece=ering\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1700 all=16143 active=1252 piece=▁heard\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1720 all=16156 active=1014 piece=▁Q\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1740 all=16253 active=1111 piece=fter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1760 all=16306 active=1164 piece=▁able\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1780 all=16318 active=1176 piece=aughter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1800 all=16344 active=1202 piece=000\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1820 all=16429 active=1081 piece=lish\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: m_bpe.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: m_bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "SentencePieceTrainer.train(\n",
    "    '--input=all_comments_text.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe'\n",
    ")\n",
    "\n",
    "m_bpe_processor = SentencePieceProcessor()\n",
    "m_bpe_processor.load('m_bpe.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
